---
title: "Tutorial: Analyzing Survey Data (Part 1)"
author: ""
date: ""
output:
  html_document:
    css: style.css
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---
  
Chao-Yo Cheng\
31 January 2021

## Before You Start: Descriptive Statistics Using R

- "[Quick R](https://www.statmethods.net/stats/descriptives.html)" (Robert I. Kabacoff)
- "[Descriptive Statistics in R](https://statsandr.com/blog/descriptive-statistics-in-r/)" (Antoine Soetewey)
- "[Modern R with the Tidyverse](https://b-rodrigues.github.io/modern_R/)" (Bruno Rodrigues) (Chapter 4)

## 1 Introduction

Our objectives today include:
  
  - Set up a `survey` object using survey design information, such as sample weight and stratification variables.
- Use a `tidyverse` approach to study descriptive statistics.

We will use the package `survey` and a tidyverse-style wrapper called `srvyr` (pronounced as "surveyor").

```{r, echo=T, eval=T, message=F}
library(survey)
library(srvyr)
```

If you have yet to install the packages, use the function `install.packages()`.

```{r, echo=T, eval=F}
install.packages("survey")
install.packages("srvyr")
```

Make sure you load the following packages, too:
  
  ```{r, echo=T, eval=T, message=F}
library(dplyr)
library(ggplot2)
library(purrr)
```

> *Question: Can you use a few words (or sentences) to describe what each of these packages does?*
  ## 2 Data
  
  The sample dataset for today's tutorial is from the 2011 <a href="http://www.ces-eec.ca/" target="_blank">Canadian National Election Study</a>. You can also retrieve the dataset from the `carData` package (see below). You can also find the .csv file on **Moodle**.

```{r, echo=T, eval=T}
ces <- carData::CES11
```

There are 2,231 observations on the following 9 variables:

 - `id` -- a unique identifier for each response.
 - `province` -- a factor with (alphabetical) levels, including AB, BC, MB, NB, NL, NS, ON, PE, QC, SK (each of these refers to a Canadian province). The sample was "stratified" by province.
 - `population` -- population of the respondent's province (number of people over age 17).
- `weight` -- weight sample to size of population, taking into account unequal sampling probabilities by province and household size.
- `abortion` -- attitude toward abortion, a factor with levels `No` and `Yes`; answer to the question "Should abortion be banned?"
- `gender` -- a factor with two levels `Female` and `Male`.
- `importance` -- importance of religion, a factor with (alphabetical) levels including `not`, `notvery`, `somewhat`, `very`; answer to the question, "In your life, would you say that religion is very important, somewhat important, not very important, or not important at all?"
- `education` -- a factor with (alphabetical) levels including `bachelors` (Bachelors degree), `college` (community college or technical school), `higher` (graduate degree), HS (high-school graduate), `lessHS` (less than high-school graduate), `somePS` (some post-secondary).
- `urban` -- place of residence, a factor with levels rural, urban.

> *Question: What is the unit of observation?*
  > *Question: When should we use stratified sampling? And how does that decision influence the distribution of respondents from different provinces when we do not use stratified sample?*
  > *Question: What is the main dependent variable of interest?*
  > *Question: Anything wrong with the current set of explanatory/independent variables or predictors? Any other factors should we consider?*
  > *Question: Can we conduct survey research with children in our sample? How should we do that?*
  Now, set up your working directory and read the data into R.

```{r, echo=T, eval=F}
ces <- read.csv("ces11.csv", stringsAsFactors=TRUE)
```
Note that here we set `stringsAsFactors=TRUE` so that the variables that are meant to be factors are set up accordingly.

> *Question: How do we verify whether or not a variable is a factor in `R`? If it is not, which `R` function should we use to force a variable to be a factor?*
  ## 3 Survey Design Components
  
  The following variables in the dataset provide the information on the survey design.

- `id` is a unique identifier for each observation.
- `province` -- the sampling was stratified by province (random sampling by landline numbers was done within province).
- `population` provides the population size of each province.
- `weight` is calculated based on differences in province population, the study sample size therein, and household size.

```{r, echo=T, eval=T}
ces %>%
  select(id, province, population, weight) %>%
  head(6)
```

> *Question: What does "select" and "head" do, respectively?*
  > *Question: Think again. How might the sample look differently if CNES used simple random sampling? Can you justify why CNES should use stratified sampling rather than simple random sampling? If they use stratified sampling, in what sense is the sample representative?*
  To use the functions contained in the `survey` and `srvyr` packages, we have to turn the `dataframe` into a `survey` objective.

```{r, echo=T, eval=T}
ces_s <- ces %>%
  as_survey(ids = id,
            strata = province,
            fpc = population,
            weights = weight)
ces_s
```

Here you can find some basic information for the survey object `ces_s`.

> *Question: Again, how can we verify that `ces_s` is really a `survey` object?*
  > *Question: In the function `as_survey`, there are four options you have to fill in -- find out what they mean according to the official package manual.*
  ## 4 Computing Descriptive Statistics
  
  Complete the following tasks.

- Drawing on the dataframe `ces`, use `tidyverse` functions to calculate the number of people who think abortion should be banned.
- Repeat the same analysis, but this time use the survey object `ces_s`. 

> *Question: Describe and explain your observations.*
  > *Question: Can you think of other descriptive analysis you can do?*
  Here is one example (more TBA after the live session) -- say, we want to use the dataframe `ces` to calculate the number of people who think abortion should be banned.

```{r, echo=T, eval=T}
ces %>%
  group_by(abortion) %>%
  summarise(n = n())
```

> *Question: How else can you get the table?*
  Now let's use `ces_s` (i.e., the survey object) and the `survey_total()` function.

```{r, echo=T, eval=T}
ces_s %>%
 group_by(abortion) %>%
 summarise(n = survey_total())
```

> *Question: What does `survey_total` do?*
> *Question: Can you the proportion of people who think abortion should be banned?*
## Additional References

John Fox and Sanford Weisberg: "Fitting regression models to data from complex surveys." -- walk through the exercise using the `survey` package.

Greg Freedman: ["`srvyr` compared to the `survey` package"](https://cran.r-project.org/web/packages/srvyr/vignettes/srvyr-vs-survey.html) -- a short tutorial from the package's author.

Arnold Lau: ["Exploring survey data with the `pewmethods` R package"](https://medium.com/pew-research-center-decoded/exploring-survey-data-with-the-pewmethods-r-package-198c4eb9d1af). -- note this is one of a series articles where Pew researchers introduce how the package they made is a good alternative to the packages we use here.

## Extra: European Social Survey (Round 9)

**This section is contributed by Dr [Andi Fugard](https://natcen.ac.uk/about-us/people/staff/andi-fugard) (NatCen) with some minor revisions by Chao-yo.**
  
  Let us work on another example using the <a href="https://www.europeansocialsurvey.org/download.html?file=ESS9e03_1&y=2018" target="_blank">European Social Survey</a> (Round 9).

To import the `SPSS` data file into `R`, we can use the package `haven`.

> *Question: The package `haven` is very powerful. What other types of data files can we import into `R` by using this package?*
  ```{r, echo=T, eval=F}
library(haven)
ess9 <- read_sav("ESS9e03.sav")
```

Whenever you import a new dataset, you should see it.

```{r, echo=T, eval=F}
View(ess9)
```

> *Question: Any other functions we can use to "see" the data?*
  > *Question: What if you just want to list variable names?*
  > *Question: Describe your observations.*
  > *Question: Perhaps you want to read the codebook -- where is it on the ESS website? It is a good exercise to spend some time looking through the documentation on the ESS website to find the variable name.*
  If that has worked -- then the next problem is finding the variables we want to analyze! 
  
  Read the following discussion from the report published by the <a href="https://www.bsa.natcen.ac.uk/latest-report/british-social-attitudes-37/fairness-and-justice-in-britain.aspx" target="_blank">British Social Attitudes</a>:
  
  >> Only 20% of the British public think that differences in wealth in Britain are fair, whilst a majority (59%) think that wealth differences in Britain are unfairly large and a further 16% think that differences in wealth are unfairly small.
The original question was

>> In your opinion, are differences in wealth in Britain unfairly small, fair, or unfairly large?
  We will also need the variable for country (easier to spot) and any information required for setting up the survey object. The ESS website advises we "must weight tables before quoting percentages from the survey." See the guide Weighting European Social Survey Data for fuller details about which weights to use (it is on Moodle).

>> The *Design weights* (`DWEIGHT`) adjust for different selection probabilities, while the *Post-stratification* weights (`PSPWGHT`) adjust for sampling error and non-response bias, as well as different selection probabilities. Either `DWEIGHT` or `PSPWGHT` must always be used. In addition, the *Population size weights* (`PWEIGHT`) should be applied if you are looking at aggregates or averages for two or more countries combined. 
### Tabulate the data by country

First, let's make the country variable look a bit nicer. It currently looks like this:

```{r, echo=T, eval=F}
table(ess9$cntry)
```

But the dataset also has nicer labels included, which we can get like this using the function `as_factor` (note the underscore). This function is in the package `haven`.

```{r, echo=T, eval=F}
ess9$cntry <- as_factor(ess9$cntry, levels = "labels")
table(ess9$cntry)
```

> *Question: Describe the differences in the output.*
### Set up the `survey` object

Now let's set up the survey object:
  
  The `nest` option takes account of the `ids` being nested within strata -- in other words, the same ID is used only once in a country although it is used more than once across the dataset.

```{r, echo=T, eval=F}
ess9_survey <- ess9 %>%
  as_survey_design(ids = idno,
                   strata = cntry,
                   nest = TRUE,
                   weights = pspwght)
```

### Try out some analysis

The country variable is `cntry` and the wealth variable is `wltdffr`. They are both explained in the online documentation.

The first thing you will spot when looking at the possible values of this variable is that the original variable is coded from -4 to 4.

```{r, echo=T, eval=F}
unique(ess9$wltdffr)
```

Let's create another variable that is grouped the same way as in the report:

```{r, echo=T, eval=F}
ess9_survey <- ess9_survey %>%
 mutate(wltdffr_group =
      case_when(
       wltdffr >= -4 & wltdffr <= -1 ~ "Unfairly small",
       wltdffr == 0 ~ "Fair",
       wltdffr >= 1 & wltdffr <= 4 ~ "Unfairly large"),
     wltdffr_group = factor(wltdffr_group,
                levels = c("Unfairly small",
                      "Fair",
                      "Unfairly large"))
 )
```

> *Question: Can you repeat the same analysis without using the `tidyverse` pipelines?*
Great, now let's see what the UK data look like for this grouped variable:
  
  ```{r, echo=T, eval=F}
gb_wealth <- ess9_survey %>%
  filter(cntry == "United Kingdom") %>%
  group_by(wltdffr_group) %>%
  summarise(prop = survey_mean(vartype = "ci"))
gb_wealth 
```

Let's round our results to see more clearly that they match the report:

```{r, echo=T, eval=F}
gb_wealth %>%
 mutate(perc = (prop*100) %>% round(0)) %>%
 select(wltdffr_group, perc) 
```

We can also plot the results:

```{r, echo=T, eval=F}
gb_wealth %>%
 filter(!is.na(wltdffr_group)) %>%
 ggplot(aes(x = wltdffr_group, y = prop*100)) +
 geom_col(fill = "#B053A1") +
 geom_errorbar(aes(ymin = prop_low*100,
          ymax = prop_upp*100), width = 0.2) +
 ylim(0,100) +
 labs(y = "%", x = NULL,
    title = "In your opinion, are differences in wealth in Britain\nunfairly small, fair, or unfairly large?")
```

Let's do it again for a selection of countries. First, make a function which carries out the analysis for one country:
  
  ```{r, echo=T, eval=F}
get_country_results <- function(the_cntry) {
  ess9_survey %>%
    filter(cntry == the_cntry) %>%
    group_by(wltdffr_group) %>%
    summarise(prop = survey_mean(vartype = "ci")) %>%
    mutate(cntry = the_cntry)
}
```

Check it works for the UK:
  
  ```{r, echo=T, eval=F}
get_country_results("United Kingdom")
```

Run it for your countries of interest:
  
  ```{r, echo=T, eval=F}
conts <- c("Germany", "Spain", "France", "United Kingdom", "Italy")
euro_wealth <- map_dfr(conts, get_country_results)
head(euro_wealth)
```

That's a lot of numbers! Let's try a plot:
  
  ```{r, echo=T, eval=F}
euro_wealth %>%
  filter(!is.na(wltdffr_group)) %>%
  ggplot(aes(x = cntry,
             y = prop*100,
             ymin = prop_low*100,
             ymax = prop_upp*100,
             fill = wltdffr_group)) +
  geom_col(position = position_dodge(width = .8), width = 0.6) + 
  geom_errorbar(position=position_dodge(width = .8),
                colour="black",
                width = 0.2) +
  ylim(0,100) +
  labs(y = "%", x = NULL,
       title = "In your opinion, are differences in wealth\nunfairly small, fair, or unfairly large?",
       fill = NULL)
```

## Extra: When Weights Come to Rescue

**You can skip this part completely.**
  
  This section presents a simulation exercise in `R` to show why weights matter. The entire simulation consists of the following process:
  
  - Create a fake population data such as there are 1,000 observations -- there is a equal number of observations from the urban and rural areas, respectively (i.e., 500 observations each). The key outcome variable in the population data is `score` (e.g., credit score of the household). 

- Use simple random sampling to create a sample of about 500 observations. Compare the weighted and unweighted average scores to the population average score.

- Use stratified (or multi-stage) samling to create another sample of about 500 observations -- however, we will set up such that the probability of being chosen is 0.25 in the countryside and 0.75 in the city.

### Set up the population

```{r, echo=T, eval=T}
sim_pop <- data.frame(id = 1:1000, # unique ID
                      score = rnorm(1000, mean=65, sd=10),
                      urban = c(rep(0,500), rep(1,500)),
                      pop = 500)
```

In this dataset,

- `id` is the unique identifier of each observation in the population.
- `score` is some made-up score for each observation -- I use `rnorm()` to generate 1,000 random numbers from a normal distribution such that the mean is 65 and the standard deviation is 10.
- `urban` is a binary variable to indicate whether the observation is in the city (=1) or not (=0).
- `pop` is the number of people living in the city and countryside with 500 each.

To make things more interesting, I multiply the scores in the city by 2.

```{r, echo=T, eval=T}
sim_pop$score[sim_pop$urban == 1] <- sim_pop$score[sim_pop$urban == 1]*2
```

The population mean is then

```{r, echo=T, eval=T}
mean(sim_pop$score)
```
or
```{r, echo=T, eval=T}
sim_pop %>%
  summarise(mean=mean(score))
```

### Create a sample with simple random sampling

We will use the function `sample()` to create a binary indicator in the population data -- when the value is 1, it means the observation is selected in the sample.

```{r, echo=T, eval=T}
sim_pop$s_simple <- sample(c(0,1), size=1000, replace=TRUE, prob=c(1/2, 1/2))
```

The function basically says: "**please take 1,000 draws and the occurrence of 0 and 1 for each draw has the same probability -- here each draw is independent from each other because the probability of having 0 (or 1) in the previous draw does not affect the probability of having 0 (or 1) in the following draw.**" Since each observation is being assigned the value of 1 with equal probability, it means the probability of being included in the sample is 500 out of 1000, which is 0.5. The sample weight is the reciprocal (or inverse proportion) of this probability, namely 2.

```{r, echo=T, eval=T}
sim_pop$w_simple <- 2
```

Now, let's create another data frame that only includes the selected observations.

```{r, echo=T, eval=T}
sam_sim <- sim_pop %>%
  filter(s_simple == 1)
```

And let's turn this into a survey subject.

```{r, echo=T, eval=T}
sam_sim_s <- sam_sim %>%
  as_survey(ids = id,
            strata = urban,
            fpc = pop,
            weight = w_simple)
```

Finally, let's compare the sample mean with and without weights. They are similar to each other -- they are also very close to the population mean.

```{r, echo=T, eval=T}
sam_sim %>% summarise(mean=mean(score)) # unweighted
sam_sim_s %>% summarise(mean=survey_mean(score)) # weighted
```

### Create a sample with stratified sampling

Let's create another sample, but with a bit more complicated sampling process. Say, now the probabilities of being included in the sample vary by urban vs rural, with 0.25 and 0.75, respectively.

```{r, echo=T, eval=T}
sim_pop$s_complex <- NA # add a column in the population data
sim_pop$s_complex[sim_pop$urban == 1] = sample(c(0,1), size=500, replace=TRUE, prob = c(1/4, 3/4))
sim_pop$s_complex[sim_pop$urban == 0] = sample(c(0,1), size=500, replace=TRUE, prob = c(3/4, 1/4))
```

Now let's set the weights for those in the city and countryside, respectively.

```{r, echo=T, eval=T}
sim_pop$w_complex <- NA
sim_pop$w_complex[sim_pop$urban == 1] <- (2/1)*(4/3)
sim_pop$w_complex[sim_pop$urban == 0] <- (2/1)*(4/3)
```

Let's create a new data frame for the new selected observations.

```{r, echo=T, eval=T}
sam_com <- sim_pop %>%
  filter(s_complex == 1)
```

Let's check to see if the sample indeed includes more observations from the city (the numbers may not be perfect here given that we draw all the sample from some random processes).

```{r, echo=T, eval=T}
sam_com %>%
  group_by(urban) %>%
  summarise(n =n())
```

And now create the corresponding survey object. Be sure to include the weights.

```{r, echo=T, eval=T}
sam_com_s <- sam_com %>%
  as_survey(ids = id,
            strata = urban,
            fpc = pop,
            weight = w_complex)
```

Finally, let's compare the sample mean with and without weights again. Now you see they are quite different (and the weighted one is closer to the population mean). The unweighted one is higher, which should not be too surprising given that urban observations are more likely to be included in the sample.

```{r, echo=T, eval=T}
sam_com %>% summarise(mean=mean(score)) # unweighted
sam_com_s %>% summarise(mean=survey_mean(score)) # weighted
```
