---
title: "Problem Set 3: Multilevel Modeling"
author: ""
date: \today
fontsize: 11pt
linestretch: "1.1"
indent: false
papersize: a4paper
format:
  pdf:
    keep-tex: false
    number-sections: true
    shift-heading-level-by: 0
    toc: false
    pdf-engine: "xelatex"
---

In this problem set, we will use multilevel modeling to study the correlates of anti-Americanism in the Muslim World. The following exercise aims to help you get a grasp of several practical matters in relation to the implementation of multilevel modeling in `R`.

Before you start, please download the dataset from GitHub and import it into `RStudio`. If you would like to submit this problem set, please complete the questions at the end.

# Variables

We will study the replication data of the following paper: 

**Blaydes, Lisa, and Drew Linzer. 2012. "Elite Competition, Religiosity, and Anti-Americanism in the Islamic World." *American Political Science Review 106*(2): 225-243.**

In this paper, Blaydes and Linzer study public opinion data from the Pew Global Attitudes Project (2007) that surveyed more than 10,000 Muslim respondents in 21 countries. The key finding of this article is a respondent's attitude towards the US is also shaped by the intensity of Reformer-Islamist struggle in their country.

Blaydes and Linzer employ a *Bayesian hierarchical model* of anti-Americanism that considers predictors at both individual- and country-levels.^[See the `R` script if you would like to see how we can use the `brms` package to run the Bayesian multilevel analysis.]

For this exercise, at **individual** level, we will pay close attention to the following variables:

  - `serial` -- a unique identifier for individual respondents.

  - `us.scale` -- a (re-scaled) continuous variable ranging from 0 (complete favorability of the United States) to 1 (the maximum level of anti-American sentiment); this variable is constructed based on seven questions in the GAP survey; this will be our dependent variable.

  - `pious` -- a binary indicator that takes the value of 1 if the respondent is highly religious.

  - `news` -- a binary indicator that takes the value of 1 if the respondent frequently follows intl news.

  - `satisfied` -- a (re-scaled) continuous variable ranging from 0 and 1 with higher value indicating more satisfaction with how things going in the corresponding country of each respondent

  - `age` -- the respondent's age; the authors divide `age` by 100 for convenience

  - `male` -- a binary variable that takes the value of 1 for male respondents

  - `ses` -- socioecononmic status

  - `ed2` -- a binary variable that takes the value of 1 if the respondent's highest level of education is secondary school

  - `ed3` -- a binary variable that takes the value of 1 if the respondent's highest level of education is university or above

Our analysis also considers the following **country**-level predictors.

  - `country` -- the unique identifier of each country included in the 2007 GAP survey

  - `struggle` -- the percentage of respondents seeing a reformer-Islamist struggle in their country

  - `pctmus` -- the percentage of Muslim in the country

  - `log.gdppc` -- (natural) log of per capita GDP

## Load Packages

We will need the following packages.

  - We will use `lattice` to visualize our results.

  - The `lme4` package includes a variety of functions to fit linear and non-linear multilevel models. We will need to use the `lmer()` function from `lme4` to carry out the (linear) multilevel/hierarchical analysis; the `lmerTest` package is required to compute the $p$-value of our point estimates.

```{r, echo=T, eval=T, message=F}
library(tidyverse)
library(lattice)
library(lme4)
library(lmerTest)
```

## Read Data

```{r, echo=F, eval=T, message=F}
setwd("C:/Users/polar/Downloads/BBK_AdvQ/08 Multilevel/Tutorials/Data")

dta_country <- readRDS("Country Covariates.RData")
dta_country$country <- rownames(dta_country)
dta_country <- dta_country %>%
  dplyr::select(struggle, # percent seeing a reformer-Islamist struggle
                pctmus, # percent Muslim in country
                log.gdppc, # (natural) log of per capita GDP
                country)

dta <- readRDS("Pew GAP 2007.RData") 
dta_gap <- dta %>%
  dplyr::select(country,
                us.scale, # Anti-Americanism scale: 1=most AA, 0=least AA
                pious, # Individual: 1=highly religious, 0=less religious
                news, # Follow intl news: 1=frequently, 0=only when important
                satisfied, # satisfied with how things going in country
                age,
                male,
                ses,
                ed2,
                ed3) %>% 
  mutate(age = age/100,
         serial = 1:nrow(dta))

dta_all <- merge(dta_gap, dta_country, by="country") %>%
  unique() %>%
  drop_na()
```

We will first read two datasets into `RStudio`. Both variables are in `.RData` format, so we will use the function `readRDS` to import them.

Each of these datasets contains variables at individual- and country-level respectively. Both datasets use the variable `country` to identify the country in which the variables are recorded, so we will use it to **merge** these two datasets.

Let's start by reading in the country-level dataset. Here we use `rownames()` to extract the row names of `dta_country` and add it to the dataframe as a new variable `country`.

```{r, echo=T, eval=F, message=F}
dta_country <- readRDS("Country Covariates.RData")
dta_country$country <- rownames(dta_country) # add "country"
dta_country <- dta_country %>%
  dplyr::select(struggle,
                pctmus,
                log.gdppc,
                country)
```

Then read in the individual-level dataset. Here we create a new variable `serial` as the unique identifier of individual observations -- the colon `:` is used to create a vector of integers starting from 1 and end at `nrow(dta)`, which refers to the total number of rows (i.e., observations) in `dta`.

```{r, echo=T, eval=F, message=F}
dta <- readRDS("Pew GAP 2007.RData") 
dta_gap <- dta %>%
  dplyr::select(country,
                us.scale,
                pious,
                news,
                satisfied,
                age,
                male,
                ses,
                ed2,
                ed3) %>% 
  mutate(age = age/100,
         serial = 1:nrow(dta))
```

Now let's use `merge()` to combine both datasets using `country`. Type `?merge` in `R` to learn more about this function.

```{r, echo=T, eval=F, message=F}
dta_all <- merge(dta_gap, dta_country, by="country") %>%
  unique() %>%
  drop_na()
``` 

Here we can use four functions to take a peak at the combined dataset.

```{r, echo=T, eval=T, message=F}
names(dta_all) # list all columns (variables)
ls(dta_all) # list all columns (variables) alphabetically
summary(dta_all) # show summary statistics
head(dta_all) # show first 6 rows
```

## Disable Scientific Notation

We will also need to use `options` at the very beginning to disable print out our results in scientific notation.

```{r, echo=T, eval=F, message=F}
options(scipen=999)
```

# Linear Multilevel Models (LMMs)

Now we will attempt different multilevel modeling approaches. For the purpose of illustration, we will only use one predictor.^[You can find an example of multiple linear multilevel models in `R`.] 

Our dependent variable is `us.scale` and the group variable is `country`. Again, when we try to set up our multilevel model, we should think through the following questions before we use *ad hoc* statistical tricks for model comparison/selection. 

  - Should we include any predictors? If yes, should we include both individual- and country-level predictors?

  - Should we allow the intercept to vary by group? Under most situations the answer is yes but it is not mandatory.

  - Should we allow the slope to vary by group? If yes, then things will get complicated if we have more than one predictor.

Since for now the model will include one predictor `ed3` for now, here we will only **four** scenarios.

  - **Varying intercept (without predictor)**: A multilevel model with no predictor; vary the intercept by country (this scenario is only for educational purpose)

  - **Varying intercept (with predictor)**: A multilevel model with one predictor; vary the intercept by country

  - **Varying slope (with predictor)**: A multilevel model with one predictor; vary the slope by country

  - **Varying intercept and slope (with predictor)**: A multilevel model with one predictor; vary both intercept and slope by country

Below are the correspondoing formal expressions and `R` code (here we use the subscript $j$ to denote a country/groop):

|                                                       | Formal expression               |
|-------------------------------------------------------|---------------------------------|
| Linear (constant $\alpha$ and $\beta$)                | $Y=\alpha+\beta X+\epsilon$     |
| Linear Multilevel (varying $\alpha$ only)             | $Y=\alpha_j+\beta X+\epsilon$   |
| Linear Multilevel (varying $\beta$ only)              | $Y=\alpha+\beta_j X+\epsilon$   |
| Linear Multilevel (varying $\alpha$ and $\beta$ only) | $Y=\alpha_j+\beta_j X+\epsilon$ |

|                                                  | `R` code                          |
|--------------------------------------------------|-----------------------------------|
| Linear (constant $\alpha$ and $\beta$)           | `lm(us.scale~ed3)`                |
| Linear Multilevel (varying $\alpha$)             | `lmer(happy~ed3+(1|country))`     |
| Linear Multilevel (varying $\beta$)              | `lmer(happy~ed3+(0+edu|country))` |
| Linear Multilevel (varying $\alpha$ and $\beta$) | `lmer(happy~ed3+(edu|country))` |

## Varying Intercept w/o Predictor

If we only allow the intercept to vary by country without any predictor, we are effectively trying to fit the following model in one go with `lmer()`: $$Y=\alpha_j+\epsilon,$$ where we use the subscript $j$ to denote a country. 

Since we have 21 countries in the dataset, our goal is to find a unique estimated intercept of each country (i.e., 21 $\widehat{\alpha}$'s in total). Let's fit the model.

```{r, echo=T, eval=T, message=F}
mod_lmm_1 <- lmer(us.scale ~ 1 + (1|country), data=dta_all)
summary(mod_lmm_1)
```

The estimated intercept $\widehat{\alpha}=0.5468$ listed below `Fixed effects` in the regression output is the **mean** of all estimated intercepts across different countries. Note that this is also the estimated mean anti-Americanism sentiment across all Muslim respondents and across all countries.

In the textbook, there is also a brief discussion on **interclass correlation coefficient**, which is defined as the estimated group-level variance divided by the sum of estimated group-level and individual-level variance: $$\widehat{\rho}=\frac{\text{Between-group variance}}{\text{Between-group variance}+\text{Between-individual variance}}=\frac{0.02}{0.02+0.06}=0.25,$$ which suggests that $25\%$ of total variance in the anti-American sentiment can be attributed to variance between different countries and this is not trivial. In other words, we can use ICC to justify why we should use multilevel model to study this question. 

The default output does not show the exact estimated intercept of each country, but we can obtain them as below. 

  - Step 2: We can use `coef()` to call out the unique $\widehat{\alpha}$ of each country.

  - Step 3: Each unique $\widehat{\alpha}$ is the sum of **fixed** and **random** effects. We can use `fixef()` and `ranef()` to call them out. The fixed effect is the same across all countries as it is the mean of of all estimated intercepts across different countries; the random effect is unique for each country.

Let's proceed.

```{r, echo=T, eval=T, message=F}
coef(mod_lmm_1) # extract all unique intercepts
fixef(mod_lmm_1) # extract fixed part of each intercept
ranef(mod_lmm_1) # extract random part of each intercept
```

You can also plot the estimated intercept of each country, with the confidence interval included for each of them.

```{r, echo=T, eval=T, message=F}
dotplot(ranef(mod_lmm_1, condVar=TRUE))
```

## Varying Intercept with Predictor

Now, let's add `ed3` into the model. 

If we only allow the intercept to vary by group while including the predictor(s), basically we are trying to fit the following models: $$Y=\alpha_j+\beta X+\epsilon,$$ in which we use $j$ to denote a country. Again, our goal is to find the estimated intercept of each country.

Let's fit the model.

```{r, echo=T, eval=T, message=F}
mod_lmm_2 <- lmer(us.scale ~ ed3 + (1|country), data=dta_all)
summary(mod_lmm_2)
```

Now we can see that across all countries, on average highly educated respondents hold **less** grudge against the US. Since we do not vary the slope by country, we will not be able to see whether the correlation between higher education and anti-Americanism is different by country.

We can carry out the same process to extract the estimated intercepts of all countries and the random component of each of them.

```{r, echo=T, eval=F, message=F}
coef(mod_lmm_2) # extract all unique intercepts
fixef(mod_lmm_2) # extract fixed part of each intercept
ranef(mod_lmm_2) # extract random part of each intercept
```

And visualize the random component of each estimated intercept.

```{r, echo=T, eval=F, message=F}
dotplot(ranef(mod_lmm_2, condVar=TRUE))
```

## Varying Slope with Predictor

Say now we have some prior knowledge to posit that the intercept for each country should be the same, but each country will have a different slope. In other words, we believe the correlation between higher education and anti-Americanism varies by country.

This idea will turn our model into: $$Y=\alpha+\beta_j X+\epsilon.$$ Our objective is to find the corresponding estimated slope for each country.

```{r, echo=T, eval=T, message=F, warning=F}
mod_lmm_3 <- lmer(us.scale ~ ed3 + (0+ed3|country), data=dta_all)
summary(mod_lmm_3)
```

And let's extract each estimated slopes.

```{r, echo=T, eval=F, message=F}
coef(mod_lmm_3) # extract all unique slopes
fixef(mod_lmm_3) # extract fixed part of each slope
ranef(mod_lmm_3) # extract random part of each slope
```

Use the dotplot to show the random part of each slope.

```{r, echo=T, eval=F, message=F}
dotplot(ranef(mod_lmm_3, condVar=TRUE))
```

## Varying Intercept and Slope with Predictor

Finally, if we decide that each country should have its own unique intercept and slope, then the model becomes: $$Y=\alpha_j+\beta_j X+\epsilon.$$ 

Our objective is to find the estimated intercept and slope corresponding to each country.

```{r, echo=T, eval=T, message=F, warning=F}
mod_lmm_4 <- lmer(us.scale ~ ed3 + (ed3|country), data=dta_all)
summary(mod_lmm_4)
```

A few things to note from the repression out before we proceed:

  - In the section `Random effects`: The output shows the correlation between the group-level variance for the intercept and slope is negative ($-0.19$), suggesting that countries with higher slopes tend to have low intercepts. Sometimes this fact may have some substantive implications.  

  - In the section `Fixed effects`: Drawing on $\widehat{\beta}=-0.03$ (the mean decrease in anti-Americanism as we increase the level of education), on average, higher education is still negatively correlated with anti-Americanism, but the level of statistical significance drops drastically once we allow both intercepts and slopes to vary by country. This finding tells us that highly educated respondents are not always more favorable towards the US in some countries.

And let's extract each estimated intercept and slope.

```{r, echo=T, eval=F, message=F}
coef(mod_lmm_4) # extract all unique intercepts and slopes
fixef(mod_lmm_4) # extract fixed part of each intercept and slope
ranef(mod_lmm_4) # extract random part of each intercept and slope
```

Use the dotplot to show the random part of each estimated intercept and slope.

```{r, echo=T, eval=F, message=F}
dotplot(ranef(mod_lmm_4, condVar=TRUE))
```

# Comparing LMMs

```{r, echo=T, eval=T, message=F, warning=F}
mod_lmm_2 <- lmer(us.scale ~ ed3 + (1|country), data=dta_all)
mod_lmm_3 <- lmer(us.scale ~ ed3 + (0+ed3|country), data=dta_all)
mod_lmm_4 <- lmer(us.scale ~ ed3 + (ed3|country), data=dta_all)
```

To compare the goodness-of-fits across different models, you can try `anova()`. We do not cover maximum likelihood estimation (MLE) here, but AIC, BIC, log-likelihood, and deviance are all typical metrics we use to evaluate model fit when we use MLE to fit GLMs.

Here you can find that `mod_lmm_4` significantly improves model fit based on the data we have.

```{r, echo=T, eval=T, message=F, warning=F}
anova(mod_lmm_2, mod_lmm_3, mod_lmm_4, test="Chisq")
```

But we can use other statistical metrics to assess model fit, too, using what you have learned -- the **sum of squared residuals** (SSR).

```{r, echo=T, eval=F, message=F, warning=F}
sum(residuals(mod_lmm_2)^2)
sum(residuals(mod_lmm_3)^2)
sum(residuals(mod_lmm_4)^2)
```

# Multilevel v Single-Level Models

Researchers who prefer multilevel/hierarchical modeling over classical (i.e., single-level) regression analysis emphasize that multilevel/hierarchical models are better suited to capture the complexities of data generation processes involving nested structures, which are not uncommon in social research.

Here we will briefly outline some explicit comparative advantages of multilevel/hierarchical modeling.

In essence, classical regression analysis imposes restrictions on how we can account for variation in estimated intercepts and slopes across groups. By default, classical regression provides only a single estimated intercept and a unique estimated slope for each specified predictor.

Nevertheless, it is possible to introduce variation in the estimated intercept across groups by incorporating **group fixed effects** in the typical one-level regression model. In doing so, a single-level regression model with group fixed effects becomes equivalent to a multilevel regression model with varying intercepts and constant slopes.

```{r, echo=T, eval=T, message=F, warning=F}
ols_country_fe <- lm(us.scale ~ as.factor(country)-1, data=dta_all)
summary(ols_country_fe)

lmm_country_fe <- lmer(us.scale ~ 1 + (1|country), data=dta_all)
coef(lmm_country_fe)
```

However, when utilizing single-level models with group fixed effects, we are unable to include group-level substantive predictors (as doing so will cause collinearity), whereas this is feasible with multilevel models.

Alternatively, it is also possible to introduce variation in the estimated slope through the inclusion of **interaction terms** in the typical one-level regression model (and this will be close to multilevel model with constant intercept and varying slopes). However, interpreting the results becomes considerably more complex as the number of groups increases.

```{r, echo=T, eval=F, message=F, warning=F}
ols_country_slo <- lm(us.scale ~ ed3 +
                      as.factor(country) + ed3:as.factor(country), data=dta_all)
summary(ols_country_slo)

lmm_country_slo <- lmer(us.scale ~ ed3 + (0+ed3|country), data=dta_all)
coef(lmm_country_slo)
```

# Questions

Find another predictor to replace `ed3` and answer the following questions.

## Question 1 {.unnumbered}

Fit a single-level OLS including the chosen predictor with and without group (country) fixed effects. Does the estimated coefficient of the predictor you choose change? Does including group (country) fixed effects help with improving the model fit?

## Question 2 {.unnumbered}

Fit the multi-level linear regression models with the chosen predictor: (1) varying intercept and constant slope and (2) varying intercept and slope. Discuss the findings. Which model performs better? 

## Question 3 {.unnumbered}

Interpret the estimated intercepts and slopes from LMM with varying intercept and slope. Does every country exhibit similar correlation with the predictor and outcome (anti-American attitudes), from the substantive point of view?

## Question 4 {.unnumbered}

Now compare single-level OLS with the LMMs you fit, which one of them performs the best?

\newpage

# Extra: Confidence Intervals of Point Estimates by Group

Characterizing the uncertainty of the point estimates produced through multilevel modeling is tricky, and researchers have been discussing about the best practice. The current standard procedure is to use the Bayesian approach to multilevel modeling (see the `R` script).

Here is one possibility to show how you derive the confidence intervals of each estimated intercept and/or slope by country using the results provided by the `lme4` package. 

The intuition is we will use the estimated upper and lower bounds of each random effect and add them to the fixed effect to derive the confidence intervals. More specifically, 

  - Step 1: Obtain the average of all estimated intercepts/slopes using `fixef()`.

  - Step 2: Obtain the random part of all estimated intercepts/slopes using `ranef()`.

  - Step 3: Turn `ranef()` into a `tibble` dataframe; the confidence interval of each estimated intercept/slope is defined as the sum of the fixed and random components, taking the standard error of each random component into consideration.

Let's use the `mod_lmm_2` as the example.

```{r, echo=T, eval=T, message=F, warning=F}
mod_lmm_2 <- lmer(us.scale ~ ed3 + (1|country), data=dta_all)
```

First, let's extract the fixed component of each estimated intercept.

```{r, echo=T, eval=T, message=F, warning=F}
lmm_2_fix <- fixef(mod_lmm_2)
lmm_2_fix
```

Next, extract the random component of each estimated intercept.

```{r, echo=T, eval=T, message=F, warning=F}
lmm_2_ran <- ranef(mod_lmm_2, condVar = TRUE)
lmm_2_ran_dd <- as.tibble(lmm_2_ran)
lmm_2_ran_dd
```

We will use the column `condsd` as the standard error of each country's estimated intercept. The column `condval` is the random component of each estimated intercept. The column `grp` (group) is the list of countries.

```{r, echo=T, eval=T, message=F, warning=F}
lmm_2_ran_dd <- lmm_2_ran_dd |>
  dplyr::select(grp, condval, condsd) |>
  rename(country = grp, ranef = condval) |>
  mutate(fixef = lmm_2_fix[1]) |>
  mutate(est = fixef + ranef,
         ci95_upper = fixef + ranef + 1.96*condsd,
         ci95_lower = fixef + ranef - 1.96*condsd)
lmm_2_ran_dd
```

# Extra: Multiple Linear Multilevel Models

Here is the model including most of the variables considered by Blaydes and Drezner. See **Table 3**. 

That being said, we will not be able to fully replicate their results since they vary the estimated slope of *all* predictors, which is way too computationally for `lmer()` (this is also why they chose the Bayesian approach).

  - `mlmm_1` -- LMM with all individual-level predictors and vary the intercept by country

  - `mlmm_2` -- LMM with all individual- and country-level predictors and vary the intercept by country

  - `mlmm_3` -- LMM with all individual- and country-level predictors and vary the intercept and the slope of `pious` by country (this is only one of the many possible model specifications)

```{r, echo=T, eval=F, message=F, warning=F}
mlmm_1 <- lmer(us.scale ~ pious + news + age + male + ed2 + ed3 + ses + satisfied
   + (1|country), data=dta_all)
mlmm_2 <- lmer(us.scale ~ pious + news + age + male + ed2 + ed3 + ses + satisfied
   + struggle + pctmus + log.gdppc + (1|country), data=dta_all)
mlmm_3 <- lmer(us.scale ~ pious + news + age + male + ed2 + ed3 + ses + satisfied
   + struggle + pctmus + log.gdppc + (pious|country), data=dta_all)
anova(mlmm_1, mlmm_2, mlmm_3, test="Chisq")
```
